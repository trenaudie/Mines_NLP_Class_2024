{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP 2 - Cours NLP \n",
    "\n",
    "![Instructions](figs/instructions_tp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Données sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_words = 19328\n"
     ]
    }
   ],
   "source": [
    "# words = open('data/civil_mots/civil_mots.txt', 'r').read().splitlines()\n",
    "codes_mots_dir = 'data/codes_mots/'\n",
    "words = []\n",
    "for file in Path(codes_mots_dir).rglob('*.txt'):\n",
    "    with open(file, 'r') as f:\n",
    "        words.extend(f.read().splitlines())\n",
    "nb_words = len(words)\n",
    "print(\"nb_words =\", nb_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "print(chars)\n",
    "nb_chars = len(chars) + 1  # On ajoute 1 pour EOS\n",
    "print(\"nb_chars =\", nb_chars)\n",
    "# Fun fact: il n'y a pas de 'k' dans le code civil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire permettant de passer d'un caractère à son identifiant entier\n",
    "ctoi = {c:i+1 for i,c in enumerate(chars)}\n",
    "ctoi['.'] = 0\n",
    "print(\"CTOI =\", ctoi)\n",
    "# Dictionnaire permettant permettant de passer d'un entier à son caractère\n",
    "itoc = {i:s for s,i in ctoi.items()}\n",
    "print(\"ITOC =\", itoc)\n",
    "# '.' a l'indice 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Construction du jeu de données pour l'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words:list, context_size:int):\n",
    "    \"\"\"Build the dataset of the neural net for training.\n",
    "\n",
    "    Parameters:\n",
    "        words: list of words of our data corpus\n",
    "        context_size: how many characters we take to predict the next one\n",
    "\n",
    "    Returns:\n",
    "        X: inputs to the neural net\n",
    "        Y: labels\n",
    "    \"\"\"\n",
    "    X, Y = [], []\n",
    "    for w in words:\n",
    "        #print(w)\n",
    "        context = [0] * context_size\n",
    "        for ch in w + '.':\n",
    "            ix = ctoi[ch]\n",
    "            X.append(context)\n",
    "            Y.append(ix)\n",
    "            #print(''.join(itoc[i] for i in context), '--->', itoc[ix])\n",
    "            context = context[1:] + [ix] # crop and append\n",
    "    X = torch.tensor(X)\n",
    "    Y = torch.tensor(Y)\n",
    "    #print(X.shape, Y.shape)\n",
    "    return X, Y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Les mots du code civil générent un jeu d'entraînement avec les entrées `X` de dimension 2 de forme (67652, 3), soit 67652 contextes de 3 caractères différents et pour les labels `Y` 67652 caractères suivants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_size = 3\n",
    "X, Y = build_dataset(words, context_size)\n",
    "print(\"X.shape =\", X.shape)\n",
    "print(\"Y.shape =\", Y.shape)\n",
    "print(X[:5])\n",
    "print(Y[:5])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Réseau complet et entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_dims = 10  # Dimensions des embeddings\n",
    "INT_SIZE = 200\n",
    "print(\"nb_chars =\", nb_chars)\n",
    "print(\"e_dims =\", e_dims)\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Jeux d'entraînement, de développement et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80%, 10%, 10%\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "context_size = 3\n",
    "Xtr, Ytr = build_dataset(words[:n1], context_size=context_size)\n",
    "Xdev, Ydev = build_dataset(words[n1:n2], context_size=context_size)\n",
    "Xte, Yte = build_dataset(words[n2:], context_size=context_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Entraînement\n",
    "\n",
    " start a new wandb run to track this script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"nlp_project_lesmines\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\":LR,\n",
    "    \"architecture\": \"MLP_l200l\",\n",
    "    \"dataset\": \"civil_mots\",\n",
    "    \"epochs\": None,\n",
    "    \"iterations\": 100_000,\n",
    "    \"batch_size\": 32,\n",
    "    }\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "stepi = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLPv0_with_Embedding(torch.nn.Module):\n",
    "    def __init__(self, nb_chars, e_dims, context_size, INT_SIZE):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(nb_chars, e_dims)\n",
    "        self.fc1 = torch.nn.Linear(context_size*e_dims, INT_SIZE)\n",
    "        self.fc2 = torch.nn.Linear(INT_SIZE, nb_chars)\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        emb_reshaped = emb.view(-1, context_size*e_dims)\n",
    "        h = F.relu(self.fc1(emb_reshaped))\n",
    "        logits = self.fc2(h)\n",
    "        return logits\n",
    "    \n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MLPv1_with_Embedding(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 nb_chars, \n",
    "                 e_dims, \n",
    "                 context_size, \n",
    "                 hidden_sizes=[512, 1024, 512, 256],\n",
    "                 dropout_rate=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Embedding layer\n",
    "        self.embedding = torch.nn.Embedding(nb_chars, e_dims)\n",
    "        \n",
    "        # Calculate input size for first linear layer\n",
    "        input_size = context_size * e_dims\n",
    "        \n",
    "        # Create list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.extend([\n",
    "            torch.nn.Linear(input_size, hidden_sizes[0]),\n",
    "            torch.nn.LayerNorm(hidden_sizes[0]),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(dropout_rate)\n",
    "        ])\n",
    "        \n",
    "        # Hidden layers\n",
    "        for i in range(len(hidden_sizes)-1):\n",
    "            layers.extend([\n",
    "                torch.nn.Linear(hidden_sizes[i], hidden_sizes[i+1]),\n",
    "                torch.nn.LayerNorm(hidden_sizes[i+1]),\n",
    "                torch.nn.ReLU(),\n",
    "                torch.nn.Dropout(dropout_rate)\n",
    "            ])\n",
    "            \n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_sizes[-1], nb_chars))\n",
    "        \n",
    "        # Create sequential model\n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "        \n",
    "        # Initialize weights using Kaiming initialization\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, torch.nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(module.weight, nonlinearity='relu')\n",
    "                if module.bias is not None:\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "            elif isinstance(module, torch.nn.LayerNorm):\n",
    "                if module.elementwise_affine:\n",
    "                    torch.nn.init.ones_(module.weight)\n",
    "                    torch.nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Get embeddings\n",
    "        emb = self.embedding(x)\n",
    "        \n",
    "        # Reshape embeddings\n",
    "        batch_size = x.size(0)\n",
    "        emb_reshaped = emb.view(batch_size, -1)\n",
    "        \n",
    "        # Pass through network\n",
    "        logits = self.network(emb_reshaped)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "\n",
    "model = MLPv1_with_Embedding(nb_chars, e_dims, context_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(200_000)):\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (32,))\n",
    "    minibatch = Xtr[ix] #shape (32, 3)\n",
    "    # forward pass\n",
    "    logits = model(minibatch).view(-1, nb_chars) # (32, nb_chars)\n",
    "    loss = F.cross_entropy(logits, Ytr[ix])\n",
    "    accuracy = (logits.argmax(dim=1) == Ytr[ix]).float().mean()\n",
    "    # backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    stepi.append(i)\n",
    "    lossi.append(loss.log10().item())\n",
    "    wandb.log({\"loss\": loss.item(), \"step\": i})\n",
    "    wandb.log({\"accuracy\": accuracy.item(), \"step\": i})\n",
    "#print(loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(stepi, lossi)\n",
    "\n",
    "\n",
    "\n",
    "logits = model(Xtr).view(-1, nb_chars) # (32, nb_chars)\n",
    "loss = F.cross_entropy(logits, Ytr)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = model(Xdev).view(-1, nb_chars) # (32, nb_chars)    \n",
    "loss = F.cross_entropy(logits, Ydev)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize dimensions 0 and 1 of the embedding matrix C for all characters\n",
    "C = model.embedding.weight\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(C[:,0].data, C[:,1].data, s=200)\n",
    "for i in range(C.shape[0]):\n",
    "    plt.text(C[i,0].item(), C[i,1].item(), itoc[i], ha=\"center\", va=\"center\", color='white')\n",
    "plt.grid('minor')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultats\n",
    "\n",
    "### Modele v0 \n",
    "\n",
    "# Modèle MLP v0 - Analyse des Performances\n",
    "\n",
    "L'analyse du modèle MLP v0 révèle plusieurs caractéristiques notables. L'entraînement s'effectue rapidement grâce à la taille modeste du modèle, qui utilise une couche intermédiaire de dimension 200 et une fenêtre de contexte de 3 caractères.\n",
    "\n",
    "## Observations Principales\n",
    "\n",
    "Nos tests ont mis en évidence plusieurs limitations importantes :\n",
    "\n",
    "L'évolution de la fonction de perte montre une tendance à la stagnation, suggérant que le modèle atteint rapidement ses limites d'apprentissage.\n",
    "\n",
    "L'analyse de la matrice d'embedding révèle une faible différenciation entre les lettres, indiquant que le modèle ne parvient pas à capturer efficacement les distinctions subtiles entre les caractères.\n",
    "\n",
    "Les tests de génération de texte produisent des résultats peu satisfaisants, confirmant les limitations du modèle dans sa capacité à apprendre et reproduire des motifs linguistiques cohérents.\n",
    "\n",
    "Par exemple : \n",
    "- alniuéeul.\n",
    "- aee.\n",
    "- pi.\n",
    "- nén.\n",
    "- rveeresroeer.\n",
    "- ra.\n",
    "- buiseeubult.\n",
    ".\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Face à ces résultats, deux pistes d'amélioration se présentent :\n",
    "- Augmentation significative de la taille du modèle pour améliorer sa capacité d'apprentissage\n",
    "- Adoption d'une architecture alternative mieux adaptée à la tâche de génération de texte\n",
    "\n",
    "![Modele v0 - Loss](figs/modelev0.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Modèle v1 - Évolutions et Résultats\n",
    "\n",
    "## Modifications Architecturales\n",
    "\n",
    "Le modèle v1 introduit plusieurs améliorations significatives par rapport à son prédécesseur :\n",
    "\n",
    "L'architecture a été redimensionnée avec une augmentation notable du nombre de couches et de leurs dimensions respectives. Cette complexification s'accompagne de l'intégration de couches LayerNorm, destinées à normaliser les activations et à prévenir les problèmes classiques de gradient.\n",
    "\n",
    "## Impact sur les Performances\n",
    "\n",
    "Ces modifications ont eu des répercussions notables sur le processus d'entraînement :\n",
    "\n",
    "La vitesse d'entraînement a été significativement impactée, passant de 1500 à 292 itérations par seconde, et ce malgré l'utilisation d'une infrastructure plus puissante (2 GPU NVIDIA T10 sur Kaggle).\n",
    "\n",
    "En contrepartie, les résultats montrent une nette amélioration :\n",
    "- La fonction de perte affiche des valeurs plus faibles et une meilleure stabilité\n",
    "- La qualité des mots générés s'est considérablement améliorée\n",
    "![Mots Générés](figs/mots_generes_v1.png)\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Les premiers résultats soulignent l'importance critique de la dimension du réseau sur [note: il semble que la conclusion soit incomplète dans le texte original]\n",
    "\n",
    "![Modele v1 - Loss](figs/modelev1.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Utilisation du modèle: génération de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = [0] * context_size\n",
    "C = model.embedding.weight\n",
    "W1 = model.fc1.weight\n",
    "b1 = model.fc1.bias\n",
    "W2 = model.fc2.weight\n",
    "b2 = model.fc2.bias\n",
    "C[torch.tensor([context])].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    out = []\n",
    "    context = [0] * context_size # initialize with all ...\n",
    "    while True:\n",
    "        logits = model(torch.tensor(context).view(1,-1))\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "        context = context[1:] + [ix]\n",
    "        out.append(ix)\n",
    "        if ix == 0:\n",
    "            break\n",
    "    print(''.join(itoc[i] for i in out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pistes d'amelioration\n",
    "\n",
    "Au lieu d'utiliser un charactère par élément du dictionaire, nous pouvons les combiner, pour créer des \"tokens\" qui ont plus de sens sématiquement. \n",
    "\n",
    "Voyons l'effet d'utiliser un tokenizer pré-entrainé dans le TP suivant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
